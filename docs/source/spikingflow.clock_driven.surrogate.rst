spikingflow.clock_driven.surrogate package
==========================================

Module contents
---------------

.. automodule:: spikingflow.clock_driven.surrogate
   :members:
   :undoc-members:
   :show-inheritance:

References
----------

.. [1]	Bohte, S.M., *Error-Backpropagation in Networks of Fractionally Predictive Spiking Neurons*. Artificial Neural Networks and Machine Learning - ICANN 2011, Pt I, 2011. 6791: p. 60-68.
.. [#esser2015backpropagation]	Esser, S.K., et al., *Backpropagation for Energy-Efficient Neuromorphic Computing*. Advances in Neural Information Processing Systems 28 (NIPS 2015), 2015. 28.
.. [3]	Esser, S.K., et al., *Convolutional networks for fast, energy-efficient neuromorphic computing*. Proceedings of the National Academy of Sciences of the United States of America, 2016. 113(41): p. 11441-11446.
.. [#yin2017algorithm]	Yin, S., et al. *Algorithm and hardware design of discrete-time spiking neural networks based on back propagation with binary activations*. in 2017 IEEE Biomedical Circuits and Systems Conference (BioCAS). 2017.
.. [#STBP]	Wu, Y., et al., *Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks*. Front Neurosci, 2018. 12: p. 331.
.. [#huh2018gradient]	Huh, D. and T.J. Sejnowski, *Gradient Descent for Spiking Neural Networks*. Advances in Neural Information Processing Systems 31 (NIPS 2018), 2018. 31.
.. [#SLAYER]	Shrestha, S.B. and G. Orchard, *SLAYER: Spike Layer Error Reassignment in Time*. Advances in Neural Information Processing Systems 31 (NIPS 2018), 2018. 31.
.. [#SuperSpike]	Zenke, F. and S. Ganguli, *SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks*. Neural Comput, 2018. 30(6): p. 1514-1541.
.. [#LSNN]	Bellec, G., et al., *Long short-term memory and learning-to-learn in networks of spiking neurons*. Advances in Neural Information Processing Systems 31 (NIPS 2018), 2018. 31.
.. [#wu2019direct]	Wu, Y., et al. *Direct training for spiking neural networks: Faster, larger, better*. in Proceedings of the AAAI Conference on Artificial Intelligence. 2019.
.. [#STCA]	Gu, P., et al., *STCA: Spatio-Temporal Credit Assignment with Delayed Feedback in Deep Spiking Neural Networks*, in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence. 2019. p. 1366-1372.
.. [#neftci2019surrogate]	Neftci, E.O., H. Mostafa, and F. Zenke, *Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-based optimization to spiking neural networks*. IEEE Signal Processing Magazine, 2019. 36(6): p. 51-63.
.. [#roy2019scaling]	Roy, D., I. Chakraborty, and K. Roy, *Scaling Deep Spiking Neural Networks with Binary Stochastic Activations*. 2019 IEEE International Conference on Cognitive Computing (IEEE ICCC 2019), 2019: p. 50-58.
.. [#panda2020toward]	Panda, P., S.A. Aketi, and K. Roy, *Toward Scalable, Efficient, and Accurate Deep Spiking Neural Networks With Backward Residual Connections, Stochastic Softmax, and Hybridization*. Frontiers in Neuroscience, 2020. 14.
.. [#SNNLSTM]	Lotfi Rezaabad, A. and S. Vishwanath, *Long Short-Term Memory Spiking Networks and Their Applications*, in International Conference on Neuromorphic Systems 2020. 2020, Association for Computing Machinery: Oak Ridge, TN, USA. p. 1-9.
.. [#SNU]	Wo≈∫niak, S., et al., *Deep learning incorporating biologically inspired neural dynamics and in-memory computing*. Nature Machine Intelligence, 2020. 2(6): p. 325-336.
.. [#LISNN]	Cheng, X., et al., *LISNN: Improving Spiking Neural Networks with Lateral Interactions for Robust Object Recognition*, in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. 2020. p. 1519-1525.